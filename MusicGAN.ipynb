{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MusicGAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1P9XLdrFaz-d",
        "colab_type": "code",
        "outputId": "40a60d41-92c1-4abc-c043-bec21110f993",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        }
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import glob\n",
        "from __future__ import print_function, division\n",
        "import random\n",
        "import pickle\n",
        "from keras.layers import Input, Dense, Reshape, Dropout, CuDNNLSTM, Bidirectional\n",
        "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "from google.colab import files, drive\n",
        "from music21 import *"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEFTP6B_a3vx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_notes():\n",
        "    \"\"\" Get all the notes and chords from the midi files \"\"\"\n",
        "    if os.path.exists('midi.pickle'):\n",
        "        notes = pickle.load(open(\"midi.pickle\",\"rb\"))\n",
        "    else:\n",
        "        notes = []\n",
        "\n",
        "        for file in glob.glob(\"midi_data/*.mid\"):\n",
        "            midi = converter.parse(file)\n",
        "\n",
        "            print(\"Parsing %s\" % file)\n",
        "\n",
        "            notes_to_parse = None\n",
        "\n",
        "            try: # file has instrument parts\n",
        "                s2 = instrument.partitionByInstrument(midi)\n",
        "                notes_to_parse = s2.parts[0].recurse() \n",
        "            except: # file has notes in a flat structure\n",
        "                notes_to_parse = midi.flat.notes\n",
        "                \n",
        "            for element in notes_to_parse:\n",
        "                if isinstance(element, note.Note):\n",
        "                    notes.append(str(element.pitch))\n",
        "                elif isinstance(element, chord.Chord):\n",
        "                    notes.append('.'.join(str(n) for n in element.normalOrder))\n",
        "        with open('midi.pickle', 'wb') as filepath:\n",
        "                pickle.dump(notes, filepath)\n",
        "    return notes\n",
        "\n",
        "def prepare_sequences(notes, n_vocab):\n",
        "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
        "    sequence_length = 100\n",
        "\n",
        "    # Get all pitch names\n",
        "    pitchnames = sorted(set(item for item in notes))\n",
        "\n",
        "    # Create a dictionary to map pitches to integers\n",
        "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
        "\n",
        "    network_input = []\n",
        "    network_output = []\n",
        "\n",
        "    # create input sequences and the corresponding outputs\n",
        "    for i in range(0, len(notes) - sequence_length, 1):\n",
        "        sequence_in = notes[i:i + sequence_length]\n",
        "        sequence_out = notes[i + sequence_length]\n",
        "        network_input.append([note_to_int[char] for char in sequence_in])\n",
        "        network_output.append(note_to_int[sequence_out])\n",
        "\n",
        "    n_patterns = len(network_input)\n",
        "\n",
        "    # Reshape the input into a format compatible with LSTM layers\n",
        "    network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
        "    \n",
        "    # Normalize input between -1 and 1\n",
        "    network_input = (network_input - float(n_vocab)/2) / (float(n_vocab)/2)\n",
        "    network_output = np_utils.to_categorical(network_output)\n",
        "\n",
        "    return (network_input, network_output)\n",
        "\n",
        "def generate_notes(model, network_input, n_vocab):\n",
        "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
        "    # pick a random sequence from the input as a starting point for the prediction\n",
        "    start = numpy.random.randint(0, len(network_input)-1)\n",
        "    \n",
        "    # Get pitch names and store in a dictionary\n",
        "    pitchnames = sorted(set(item for item in notes))\n",
        "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
        "\n",
        "    pattern = network_input[start]\n",
        "    prediction_output = []\n",
        "\n",
        "    # generate 500 notes\n",
        "    for note_index in range(500):\n",
        "        prediction_input = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "        prediction_input = prediction_input / float(n_vocab)\n",
        "\n",
        "        prediction = model.predict(prediction_input, verbose=0)\n",
        "\n",
        "        index = numpy.argmax(prediction)\n",
        "        result = int_to_note[index]\n",
        "        prediction_output.append(result)\n",
        "        \n",
        "        pattern = numpy.append(pattern,index)\n",
        "        #pattern.append(index)\n",
        "        pattern = pattern[1:len(pattern)]\n",
        "\n",
        "    return prediction_output\n",
        "  \n",
        "def create_midi(prediction_output, filename):\n",
        "    \"\"\" convert the output from the prediction to notes and create a midi file\n",
        "        from the notes \"\"\"\n",
        "    offset = 0\n",
        "    output_notes = []\n",
        "\n",
        "    # create note and chord objects based on the values generated by the model\n",
        "    for item in prediction_output:\n",
        "        pattern = item[0]\n",
        "        # pattern is a chord\n",
        "        if ('.' in pattern) or pattern.isdigit():\n",
        "            notes_in_chord = pattern.split('.')\n",
        "            notes = []\n",
        "            for current_note in notes_in_chord:\n",
        "                new_note = note.Note(int(current_note))\n",
        "                new_note.storedInstrument = instrument.Piano()\n",
        "                notes.append(new_note)\n",
        "            new_chord = chord.Chord(notes)\n",
        "            new_chord.offset = offset\n",
        "            output_notes.append(new_chord)\n",
        "        # pattern is a note\n",
        "        else:\n",
        "            new_note = note.Note(pattern)\n",
        "            new_note.offset = offset\n",
        "            new_note.storedInstrument = instrument.Piano()\n",
        "            output_notes.append(new_note)\n",
        "\n",
        "        # increase offset each iteration so that notes do not stack\n",
        "        offset += 0.5\n",
        "\n",
        "    midi_stream = stream.Stream(output_notes)\n",
        "    midi_stream.write('midi', fp='{}.mid'.format(filename))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGlBD8LAa3yA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GAN():\n",
        "    def __init__(self, rows):\n",
        "        self.seq_length = rows\n",
        "        self.seq_shape = (self.seq_length, 1)\n",
        "        self.latent_dim = 1000\n",
        "        self.disc_loss = []\n",
        "        self.gen_loss =[]\n",
        "        \n",
        "        optimizer = Adam(0.0002, 0.5)\n",
        "\n",
        "        # Build and compile the discriminator\n",
        "        self.discriminator = self.build_discriminator()\n",
        "        self.discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "        # Build the generator\n",
        "        self.generator = self.build_generator()\n",
        "\n",
        "        # The generator takes noise as input and generates note sequences\n",
        "        z = Input(shape=(self.latent_dim,))\n",
        "        generated_seq = self.generator(z)\n",
        "\n",
        "        # For the combined model we will only train the generator\n",
        "        self.discriminator.trainable = False\n",
        "\n",
        "        # The discriminator takes generated images as input and determines validity\n",
        "        validity = self.discriminator(generated_seq)\n",
        "\n",
        "        # The combined model  (stacked generator and discriminator)\n",
        "        # Trains the generator to fool the discriminator\n",
        "        self.combined = Model(z, validity)\n",
        "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "    def build_discriminator(self):\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(CuDNNLSTM(512, input_shape=self.seq_shape, return_sequences=True))\n",
        "        model.add(Bidirectional(CuDNNLSTM(512)))\n",
        "        model.add(Dense(512))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dense(256))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "        model.summary()\n",
        "\n",
        "        seq = Input(shape=self.seq_shape)\n",
        "        validity = model(seq)\n",
        "\n",
        "        return Model(seq, validity)\n",
        "      \n",
        "    def build_generator(self):\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Dense(256, input_dim=self.latent_dim))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Dense(512))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Dense(1024))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Dense(np.prod(self.seq_shape), activation='tanh'))\n",
        "        model.add(Reshape(self.seq_shape))\n",
        "        model.summary()\n",
        "        \n",
        "        noise = Input(shape=(self.latent_dim,))\n",
        "        seq = model(noise)\n",
        "\n",
        "        return Model(noise, seq)\n",
        "\n",
        "    def train(self, notes, epochs, batch_size=128, sample_interval=50):\n",
        "\n",
        "        # Load and convert the data\n",
        "        n_vocab = len(set(notes))\n",
        "        X_train, y_train = prepare_sequences(notes, n_vocab)\n",
        "\n",
        "        # Adversarial ground truths\n",
        "        real = np.ones((batch_size, 1))\n",
        "        fake = np.zeros((batch_size, 1))\n",
        "        \n",
        "        # Training the model\n",
        "        for epoch in range(epochs):\n",
        "\n",
        "            # Training the discriminator\n",
        "            # Select a random batch of note sequences\n",
        "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "            real_seqs = X_train[idx]\n",
        "\n",
        "            # noise = np.random.choice(range(484), (batch_size, self.latent_dim))\n",
        "            # noise = (noise-242)/242\n",
        "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
        "\n",
        "            # Generate a batch of new note sequences\n",
        "            gen_seqs = self.generator.predict(noise)\n",
        "\n",
        "            # Train the discriminator\n",
        "            d_loss_real = self.discriminator.train_on_batch(real_seqs, real)\n",
        "            d_loss_fake = self.discriminator.train_on_batch(gen_seqs, fake)\n",
        "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "\n",
        "            #  Training the Generator\n",
        "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
        "\n",
        "            # Train the generator (to have the discriminator label samples as real)\n",
        "            g_loss = self.combined.train_on_batch(noise, real)\n",
        "\n",
        "            # Print the progress and save into loss lists\n",
        "            if epoch % sample_interval == 0:\n",
        "              print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
        "              self.disc_loss.append(d_loss[0])\n",
        "              self.gen_loss.append(g_loss)\n",
        "        \n",
        "    def plot_loss(self):\n",
        "        plt.plot(self.disc_loss, c='red')\n",
        "        plt.plot(self.gen_loss, c='blue')\n",
        "        plt.title(\"GAN Loss per Epoch\")\n",
        "        plt.legend(['Discriminator', 'Generator'])\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.savefig('GAN_Loss_per_Epoch_final.png', transparent=True)\n",
        "        plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGS_MwHGa30T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "notes = get_notes()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmkmSmeYnv3m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gan = GAN(rows=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ks_e4ZfnoqHl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gan.train(notes, epochs=5000, batch_size=32, sample_interval=1)\n",
        "gan.plot_loss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7n5ra4mI6yT",
        "colab_type": "code",
        "outputId": "faa77f7e-69d2-4d99-a9f8-d99868e388d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "\"\"\"\n",
        "This will work sometimes and not work other times.\n",
        "There's an issue with the mapping of outputs to notes\n",
        "\"\"\"\n",
        "def generate(g, input_notes):\n",
        "        # Get pitch names and store in a dictionary\n",
        "        notes = input_notes\n",
        "        pitchnames = sorted(set(item for item in notes))\n",
        "        \n",
        "        # Use random noise to generate sequences\n",
        "        noise = np.random.normal(0, 1, (1, g.latent_dim))\n",
        "        predictions = g.generator.predict(noise)\n",
        "        \n",
        "        n = len(pitchnames) / 2\n",
        "        pred_notes = [x*n+n for x in predictions[0]]\n",
        "        # pred_notes = [x*242+242 for x in predictions[0]]\n",
        "        pred_notes = [int_to_note[int(x)] for x in pred_notes]\n",
        "        \n",
        "        create_midi(pred_notes, 'gan_final')\n",
        "\n",
        "generate(gan,notes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "154.0\n",
            "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307])\n",
            "[array([169.55989], dtype=float32), array([218.30753], dtype=float32), array([307.99875], dtype=float32), array([54.403862], dtype=float32), array([197.0114], dtype=float32), array([307.92044], dtype=float32), array([302.3554], dtype=float32), array([274.92636], dtype=float32), array([95.99198], dtype=float32), array([305.0236], dtype=float32), array([242.51248], dtype=float32), array([307.9995], dtype=float32), array([203.09442], dtype=float32), array([228.60468], dtype=float32), array([209.22238], dtype=float32), array([307.99985], dtype=float32), array([283.47516], dtype=float32), array([307.4001], dtype=float32), array([213.54922], dtype=float32), array([7.4555206], dtype=float32), array([247.8669], dtype=float32), array([265.25354], dtype=float32), array([307.97253], dtype=float32), array([109.212524], dtype=float32), array([223.1915], dtype=float32), array([14.066696], dtype=float32), array([0.3033905], dtype=float32), array([277.39825], dtype=float32), array([199.2875], dtype=float32), array([307.71112], dtype=float32), array([296.4511], dtype=float32), array([11.256943], dtype=float32), array([307.98724], dtype=float32), array([305.13226], dtype=float32), array([257.08115], dtype=float32), array([307.82806], dtype=float32), array([307.80893], dtype=float32), array([134.11545], dtype=float32), array([0.00039673], dtype=float32), array([307.25552], dtype=float32), array([307.8261], dtype=float32), array([302.83472], dtype=float32), array([234.40819], dtype=float32), array([303.39084], dtype=float32), array([5.473587], dtype=float32), array([292.86664], dtype=float32), array([294.06134], dtype=float32), array([55.33152], dtype=float32), array([307.9995], dtype=float32), array([0.02590942], dtype=float32), array([57.036064], dtype=float32), array([114.08656], dtype=float32), array([306.55786], dtype=float32), array([307.99594], dtype=float32), array([257.60202], dtype=float32), array([0.00068665], dtype=float32), array([287.80286], dtype=float32), array([290.01508], dtype=float32), array([1.5070496], dtype=float32), array([286.43527], dtype=float32), array([280.87704], dtype=float32), array([96.06595], dtype=float32), array([307.95386], dtype=float32), array([307.0807], dtype=float32), array([118.4509], dtype=float32), array([275.39276], dtype=float32), array([125.7892], dtype=float32), array([299.9826], dtype=float32), array([88.49852], dtype=float32), array([281.5102], dtype=float32), array([273.08362], dtype=float32), array([307.95312], dtype=float32), array([272.59683], dtype=float32), array([14.407333], dtype=float32), array([306.43008], dtype=float32), array([206.29819], dtype=float32), array([306.65878], dtype=float32), array([307.7691], dtype=float32), array([241.03334], dtype=float32), array([305.02853], dtype=float32), array([306.2653], dtype=float32), array([306.42746], dtype=float32), array([307.59088], dtype=float32), array([306.9453], dtype=float32), array([0.02244568], dtype=float32), array([302.30328], dtype=float32), array([307.99994], dtype=float32), array([302.6178], dtype=float32), array([307.65985], dtype=float32), array([307.00424], dtype=float32), array([304.33237], dtype=float32), array([307.9835], dtype=float32), array([8.316696], dtype=float32), array([307.99844], dtype=float32), array([307.99713], dtype=float32), array([0.18171692], dtype=float32), array([288.24207], dtype=float32), array([307.9864], dtype=float32), array([307.4051], dtype=float32), array([307.86243], dtype=float32)]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}